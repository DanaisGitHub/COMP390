{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mysql.connector.connection_cext.CMySQLConnection object at 0x000001068A5CAD50>\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_ranking as tfr\n",
    "import tensorflow_recommenders as tfrs\n",
    "import keras\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "from getpass import getpass\n",
    "from mysql.connector import connect, Error\n",
    "\n",
    "# Connect to database\n",
    "try:\n",
    "    with connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"mysql\",\n",
    "        database=\"Sprint1BasicEComDb\"\n",
    "    ) as connection:\n",
    "        print(connection)\n",
    "except Error as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ratings(): #TODO: like get All Books, add attributes to the query\n",
    "    query = \"SELECT userId,bookId,rating FROM UserBookRatings\"\n",
    "    # incase connection is lost, reconnect\n",
    "    connection.reconnect(attempts=3, delay=5)\n",
    "    mydb = connection.cursor()\n",
    "    mydb.execute(query)\n",
    "    user_ratings = mydb.fetchall()\n",
    "    return user_ratings\n",
    "\n",
    "\n",
    "def get_all_books_metadata():\n",
    "    query =\"\"\" \n",
    "    \"\"\"\n",
    "    # incase connection is lost, reconnect\n",
    "    connection.reconnect(attempts=3, delay=5)\n",
    "    mydb = connection.cursor()\n",
    "    mydb.execute(query)\n",
    "    all_books = mydb.fetchall()\n",
    "    return all_books\n",
    "\n",
    "\n",
    "def get_all_users_metadata():\n",
    "    query = \"SELECT id,birthDate,sex FROM Users\"\n",
    "    # incase connection is lost, reconnect\n",
    "    connection.reconnect(attempts=3, delay=5)\n",
    "    mydb = connection.cursor()\n",
    "    mydb.execute(query)\n",
    "    all_users = mydb.fetchall()\n",
    "    return all_users\n",
    "\n",
    "\n",
    "def save_to_csv(data, filename, header):\n",
    "    df = pd.DataFrame(data).set_axis(header, axis=1)\n",
    "    df.to_csv(filename, index=False, )\n",
    "    \n",
    "#save_to_csv(get_user_ratings(), 'user_ratings.csv', ['user_id', 'movie_title', 'rating'])\n",
    "#save_to_csv(get_all_books(), 'all_books.csv', ['book_id', 'book_title', 'description', 'num_pages', 'rating', 'num_of_voters','genres','formats','authors'])\n",
    "#save_to_csv(get_all_users(), 'all_users.csv', ['user_id', 'birth_date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_user_ratings()\n",
    "user_ratings_ids = pd.DataFrame(df, columns=[\"user_id\", \"movie_title\", \"user_rating\"])\n",
    "\n",
    "# convert to string\n",
    "user_ratings_ids['user_id'] = user_ratings_ids['user_id'].astype(str)\n",
    "user_ratings_ids['movie_title'] = user_ratings_ids['movie_title'].astype(str)\n",
    "\n",
    "rating_rank = user_ratings_ids[['user_id', 'movie_title', 'user_rating']].copy()\n",
    "book_rank = user_ratings_ids[['movie_title']].copy()\n",
    "\n",
    "user_ratings_ids=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tf.data.Dataset from the dataframe\n",
    "# Will cause error if ran again\n",
    "\n",
    "books = tf.data.Dataset.from_tensor_slices(dict(book_rank)) # book_rank only \n",
    "books = books.map(lambda x: x[\"movie_title\"])\n",
    "\n",
    "\n",
    "rating_rank = tf.data.Dataset.from_tensor_slices(dict(rating_rank))\n",
    "rating_rank = rating_rank.map(lambda x: {\n",
    "    'user_id': x['user_id'],\n",
    "    'movie_title': x['movie_title'],\n",
    "    'user_rating': x['user_rating'],\n",
    "})\n",
    "\n",
    "## new \n",
    "\n",
    "unique_books = np.unique(np.concatenate(list(books.batch(1000)))) # is it correct IDK # should be strings\n",
    "\n",
    "unique_user_ids = np.unique(np.concatenate(list(rating_rank.batch(1_000).map(lambda x: x['user_id'])))) ## could be book id\n",
    "\n",
    "# decode from bytes to string\n",
    "unique_books = [book.decode('utf-8') for book in unique_books]\n",
    "unique_user_ids = [user_id.decode('utf-8') for user_id in unique_user_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec={'user_id': TensorSpec(shape=(), dtype=tf.string, name=None), 'movie_title': TensorSpec(shape=(5,), dtype=tf.string, name=None), 'user_rating': TensorSpec(shape=(5,), dtype=tf.float64, name=None)}>\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "# do we have 100_000 ratings? # user_ratings needs to be a new type\n",
    "shuffled = rating_rank.shuffle(\n",
    "    100, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(70)\n",
    "\n",
    "test = shuffled.skip(70).take(30)\n",
    "\n",
    "# We sample 50 lists for each user for the training data. For each list we\n",
    "# sample 5 movies from the movies the user rated.\n",
    "train = tfrs.examples.movielens.sample_listwise(\n",
    "    train,\n",
    "    num_list_per_user=50,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")\n",
    "test = tfrs.examples.movielens.sample_listwise( ## making test empty\n",
    "    test,\n",
    "    num_list_per_user=1,\n",
    "    num_examples_per_list=5,\n",
    "    seed=42\n",
    ")\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tfrs.Model):\n",
    "\n",
    "  def __init__(self, loss):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_user_ids),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 2, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for movies.\n",
    "    self.movie_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_books),\n",
    "      tf.keras.layers.Embedding(len(unique_books) + 2, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.score_model = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "    self.task = tfrs.tasks.Ranking(\n",
    "      loss=loss,\n",
    "      metrics=[\n",
    "        tfr.keras.metrics.NDCGMetric(name=\"ndcg_metric\"),\n",
    "        tf.keras.metrics.RootMeanSquaredError()\n",
    "      ]\n",
    "    )\n",
    "\n",
    "  def call(self, features):\n",
    "    # We first convert the id features into embeddings.\n",
    "    # User embeddings are a [batch_size, embedding_dim] tensor.\n",
    "    user_embeddings = self.user_embeddings(features[\"user_id\"])\n",
    "\n",
    "    # Movie embeddings are a [batch_size, num_movies_in_list, embedding_dim]\n",
    "    # tensor.\n",
    "    movie_embeddings = self.movie_embeddings(features[\"movie_title\"])\n",
    "\n",
    "    # We want to concatenate user embeddings with movie emebeddings to pass\n",
    "    # them into the ranking model. To do so, we need to reshape the user\n",
    "    # embeddings to match the shape of movie embeddings.\n",
    "    list_length = features[\"movie_title\"].shape[1]\n",
    "    user_embedding_repeated = tf.repeat(\n",
    "        tf.expand_dims(user_embeddings, 1), [list_length], axis=1)\n",
    "\n",
    "    # Once reshaped, we concatenate and pass into the dense layers to generate\n",
    "    # predictions.\n",
    "    concatenated_embeddings = tf.concat(\n",
    "        [user_embedding_repeated, movie_embeddings], 2)\n",
    "\n",
    "    return self.score_model(concatenated_embeddings)\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    scores = self(features)\n",
    "\n",
    "    return self.task(\n",
    "        labels=labels,\n",
    "        predictions=tf.squeeze(scores, axis=-1),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "cached_train = train.shuffle(100).batch(8192).cache()\n",
    "print(len(cached_train))\n",
    "cached_test = test.batch(4096).cache()\n",
    "print (len(cached_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 5s 5s/step - ndcg_metric: 0.7020 - root_mean_squared_error: 4.3727 - loss: 4.7887 - regularization_loss: 0.0000e+00 - total_loss: 4.7887\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 16ms/step - ndcg_metric: 0.8664 - root_mean_squared_error: 4.3732 - loss: 4.7426 - regularization_loss: 0.0000e+00 - total_loss: 4.7426\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 17ms/step - ndcg_metric: 0.8728 - root_mean_squared_error: 4.3824 - loss: 4.6746 - regularization_loss: 0.0000e+00 - total_loss: 4.6746\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 17ms/step - ndcg_metric: 0.8214 - root_mean_squared_error: 4.3423 - loss: 4.5588 - regularization_loss: 0.0000e+00 - total_loss: 4.5588\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 18ms/step - ndcg_metric: 0.8054 - root_mean_squared_error: 4.3068 - loss: 4.3445 - regularization_loss: 0.0000e+00 - total_loss: 4.3445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x106bec98210>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listwise_model = RankingModel(tfr.keras.losses.ListMLELoss())\n",
    "listwise_model.compile(optimizer=tf.keras.optimizers.Adagrad(0.1))\n",
    "listwise_model.fit(cached_train, epochs=5, verbose=True)  # error here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step - ndcg_metric: 0.6607 - root_mean_squared_error: 1.9983 - loss: 4.6286 - regularization_loss: 0.0000e+00 - total_loss: 4.6286\n",
      "NDCG of the ListMLE model: 0.6607\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: easy_listwise_model_saved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: easy_listwise_model_saved\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "listwise_model_result = listwise_model.evaluate(cached_test, return_dict=True)\n",
    "print(\"NDCG of the ListMLE model: {:.4f}\".format(listwise_model_result[\"ndcg_metric\"]))\n",
    "listwise_model.save(\"easy_listwise_model_saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n",
      "array([[[0.43344492],\n",
      "        [0.12169501],\n",
      "        [0.46525118],\n",
      "        [0.31846273],\n",
      "        [0.16784719]]], dtype=float32)>, <tf.Tensor: shape=(1, 5, 1), dtype=float32, numpy=\n",
      "array([[[0.42098093],\n",
      "        [0.08873773],\n",
      "        [0.43597856],\n",
      "        [0.28630453],\n",
      "        [0.1273804 ]]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "predictions = listwise_model({\n",
    "    \"user_id\": tf.constant([\"42\"]),\n",
    "    \"movie_title\": tf.constant([[\"1\", \"2\", \"3\", \"4\", \"5\"]])\n",
    "})\n",
    "\n",
    "loaded_model = keras.models.load_model('easy_listwise_model_saved')\n",
    "\n",
    "\n",
    "def make_predictions(model, user_id, books_lists): # model, user_id:str[], books_lists:str[[]], has to be equal lengths\n",
    "    predictions = []\n",
    "    for i in range(len(books_lists)):\n",
    "        predictions.append( model({\n",
    "            \"user_id\": tf.constant([user_id[i]]),\n",
    "            \"movie_title\": tf.constant([books_lists[i]])\n",
    "        }))\n",
    "    return predictions\n",
    "\n",
    "predictions = make_predictions(listwise_model, [\"1\",\"2\"], [[\"1\", \"2\", \"3\", \"4\", \"5\"],[\"1\", \"2\", \"3\", \"4\", \"5\"]])\n",
    "\n",
    "\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
